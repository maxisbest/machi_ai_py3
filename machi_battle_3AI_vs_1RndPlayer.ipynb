{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...end...\n",
      "{'load': True, 'name': '', 'verbose': True, 'use_max_probability': True, 'shared_ai': True, 'game_record_filename': 'battle_log.log', 'prob_mod': 0.0, 'g_shuffle': False}\n"
     ]
    }
   ],
   "source": [
    "# tf.__version__ = 1.13.1; np.__version__ = 1.16.3\n",
    "\n",
    "from game import Game\n",
    "from player import Player\n",
    "from rnd_player import RndPlayer\n",
    "from player_ai import SharedAI\n",
    "from constants import *\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "#BUILDING ORDER\n",
    "# BUILDING_ORDER_ = BUILDING_ORDER + ['DO NOT BUY']\n",
    "\n",
    "#when in training, you need to set ğŸ“Œ load=False; ğŸ“Œ use_max_probability=True; ğŸ“Œ g_shuffle=True\n",
    "# the following setting is for battle.\n",
    "kwargs = {'load':True,\n",
    "          'name':'',\n",
    "          'verbose':True,\n",
    "          'use_max_probability':True,\n",
    "          'shared_ai':True,\n",
    "          'game_record_filename':'battle_log.log',  #è¿™ä¸ªå€¼è®¾ä¸º''å°±ä¸ä¼šè®°å½•æˆ˜æ–—è¿‡ç¨‹äº†\n",
    "          'prob_mod':0.0,\n",
    "          'g_shuffle':False\n",
    "         }\n",
    "print(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\maxyi\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\maxyi\\envs\\tfenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From c:\\users\\maxyi\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "loaded ai\n",
      "Beginning game #0\n",
      "roll dice: p3 rolled 4 with 1 dice\n",
      "roll dice: p3 rolled 6 with 1 dice\n",
      "roll dice: p3 rolled 4 with 1 dice\n",
      "roll dice: p3 rolled 3 with 1 dice\n",
      "roll dice: p3 rolled 5 with 1 dice\n",
      "roll dice: p3 rolled 6 with 1 dice\n",
      "roll dice: p3 rolled 2 with 1 dice\n",
      "roll dice: p3 rolled 5 with 1 dice\n",
      "roll dice: p3 rolled 5 with 1 dice\n",
      "roll dice: p3 rolled 4 with 1 dice\n",
      "roll dice: p3 rolled 2 with 1 dice\n",
      "roll dice: p3 rolled 6 with 1 dice\n",
      "roll dice: p3 rolled 5 with 1 dice\n",
      "roll dice: p3 rolled 1 with 1 dice\n",
      "roll dice: p3 rolled 1 with 1 dice\n",
      "roll dice: p3 rolled 4 with 1 dice\n",
      "roll dice: p3 rolled 6 with 1 dice\n",
      "roll dice: p3 rolled 3 with 1 dice\n",
      "roll dice: p3 rolled 2 with 1 dice\n",
      "Player 2, order 2 won in 79 turns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<player.Player at 0x1f6c1439048>,\n",
       " <player.Player at 0x1f6c14390b8>,\n",
       " <player.Player at 0x1f6c1439128>,\n",
       " <rnd_player.RndPlayer at 0x1f6c1421f98>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load, name, verbose = kwargs['load'], kwargs['name'], kwargs['verbose']\n",
    "# use_max_probability = kwargs['use_max_probability']\n",
    "load = kwargs['load']\n",
    "name = kwargs['name']\n",
    "USE_SHARED = kwargs['shared_ai']\n",
    "# kwargs['game_record_filename'] = ''  #ä¸è®°å½•å¯¹æˆ˜è¿‡ç¨‹\n",
    "\n",
    "# create players\n",
    "game = Game(0, name=name, options=kwargs)  #this is necessary for initiate a player\n",
    "players = game.players  #the default setting has 4 AI players\n",
    "\n",
    "# you can manipulate the players' attributes and methods\n",
    "if load:\n",
    "    players[0].load_ai(USE_SHARED)  #in this test, USE_SHARED=True; load player[0] with trained weights. this is already done by game=Game('... '). just \n",
    "\n",
    "players[3] = RndPlayer(game, order=3, coins=3)\n",
    "\n",
    "shared_ai = SharedAI(players)  #all four AI player share one set of neural networks, base_player is players[0]; RndPlayer()ä¹Ÿéœ€è¦ä¸€ä¸ªAI, å…å¾—é‡å†™\"self.dice_history = []\"è¿™äº›è¯­å¥\n",
    "\n",
    "game.players=players # = Game(0, players, options=kwargs)\n",
    "\n",
    "\n",
    "game.run()  #  å…ˆè·‘ä¸€è½®çœ‹çœ‹\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RndPlayer as Player 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ai\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n"
     ]
    }
   ],
   "source": [
    "# RndPlayer as Player 3 -- çœ‹çœ‹éšæœºç©å®¶åœ¨1000ç›˜ä¸­èƒ½å¤Ÿèµ¢å¤šå°‘ç›˜, è®¾å®šéšæœºç©å®¶.order=3\n",
    "\n",
    "load = kwargs['load']\n",
    "name = kwargs['name']\n",
    "USE_SHARED = kwargs['shared_ai']\n",
    "kwargs['game_record_filename'] = ''  #ä¸è®°å½•å¯¹æˆ˜è¿‡ç¨‹\n",
    "\n",
    "# create players\n",
    "game = Game(0, name=name, options=kwargs)  #this is necessary for initiate a player\n",
    "players = game.players  #the default setting has 4 AI players\n",
    "\n",
    "# you can manipulate the players' attributes and methods\n",
    "if load:\n",
    "    players[0].load_ai(USE_SHARED)  #in this test, USE_SHARED=True; load player[0] with trained weights. this is already done by game=Game('... '). just \n",
    "\n",
    "# å¼•å…¥éšæœºç©å®¶, å…ˆè®©å…¶åœ¨ååœ¨åº§ä½ 3 (player.order = 3) ã€‚\n",
    "players[3] = RndPlayer(game, order=3, coins=3)\n",
    "\n",
    "shared_ai = SharedAI(players)  #all four AI player share one set of neural networks, base_player is players[0]; RndPlayer()ä¹Ÿéœ€è¦ä¸€ä¸ªAI, å…å¾—é‡å†™\"self.dice_history = []\"è¿™äº›è¯­å¥\n",
    "\n",
    "\n",
    "game.players=players # = Game(0, players, options=kwargs)\n",
    "\n",
    "who_won = []\n",
    "\n",
    "for i in range(1000):\n",
    "    #game = Game(1 + i,players, options=kwargs)\n",
    "    #game.current_player = player[0]\n",
    "    for player in players:\n",
    "        player.win=0\n",
    "    \n",
    "    game.run(silent=True)\n",
    "    if i % 50 == 0:\n",
    "        print(i)\n",
    "    for player in players:\n",
    "        if player.win:\n",
    "            who_won.append(player.order)\n",
    "\n",
    "who_won_arr = np.array(who_won)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "won_by_3 = np.sum((who_won_arr == 3))  # 0\n",
    "\n",
    "won_by_0 = np.sum((who_won_arr == 0)) # 993\n",
    "\n",
    "won_by_1 = np.sum(who_won_arr == 1)  # 1\n",
    "\n",
    "won_by_2 = np.sum(who_won_arr == 2)  # 6\n",
    "\n",
    "len(who_won_arr)  #1000\n",
    "won_by_0, won_by_1, won_by_2, won_by_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players[0].decide_buy() == players[1].decide_buy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RndPlayer as Player 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ai\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n"
     ]
    }
   ],
   "source": [
    "# çœ‹çœ‹éšæœºç©å®¶åœ¨1000ç›˜ä¸­èƒ½å¤Ÿèµ¢å¤šå°‘ç›˜, è®¾å®šéšæœºç©å®¶.order=1\n",
    "\n",
    "load = kwargs['load']\n",
    "name = kwargs['name']\n",
    "USE_SHARED = kwargs['shared_ai']\n",
    "kwargs['game_record_filename'] = ''  #ä¸è®°å½•å¯¹æˆ˜è¿‡ç¨‹\n",
    "\n",
    "# create players\n",
    "game = Game(0, name=name, options=kwargs)  #this is necessary for initiate a player\n",
    "players = game.players  #the default setting has 4 AI players\n",
    "\n",
    "# you can manipulate the players' attributes and methods\n",
    "if load:\n",
    "    players[0].load_ai(USE_SHARED)  #in this test, USE_SHARED=True; load player[0] with trained weights. this is already done by game=Game('... '). just \n",
    "\n",
    "# å¼•å…¥éšæœºç©å®¶, å…ˆè®©å…¶åœ¨ååœ¨åº§ä½ 3 (player.order = 3) ã€‚\n",
    "players[1] = RndPlayer(game, order=1, coins=3)\n",
    "\n",
    "shared_ai = SharedAI(players)  #all four AI player share one set of neural networks, base_player is players[0]; RndPlayer()ä¹Ÿéœ€è¦ä¸€ä¸ªAI, å…å¾—é‡å†™\"self.dice_history = []\"è¿™äº›è¯­å¥\n",
    "\n",
    "\n",
    "game.players=players # = Game(0, players, options=kwargs)\n",
    "\n",
    "who_won = []\n",
    "\n",
    "for i in range(1000):\n",
    "    #game = Game(1 + i,players, options=kwargs)\n",
    "    #game.current_player = player[0]\n",
    "    for player in players:\n",
    "        player.win=0\n",
    "    \n",
    "    game.run(silent=True)\n",
    "    if i % 50 == 0:\n",
    "        print(i)\n",
    "    for player in players:\n",
    "        if player.win:\n",
    "            who_won.append(player.order)\n",
    "\n",
    "who_won_arr = np.array(who_won)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "995 0 5 0\n"
     ]
    }
   ],
   "source": [
    "won_by_3 = np.sum((who_won_arr == 3))  # 0\n",
    "\n",
    "won_by_0 = np.sum((who_won_arr == 0)) # 993\n",
    "\n",
    "won_by_1 = np.sum(who_won_arr == 1)  # 1\n",
    "\n",
    "won_by_2 = np.sum(who_won_arr == 2)  # 6\n",
    "\n",
    "print(len(who_won_arr))  #1000\n",
    "print(won_by_0, won_by_1, won_by_2, won_by_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
